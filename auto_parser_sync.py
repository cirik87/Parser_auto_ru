# auto_parser_sync.py (–°–ò–ù–•–†–û–ù–ù–´–ô –ü–ê–†–°–ï–† - 99% –¢–û–ß–ù–û–°–¢–¨)
"""
–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä auto.ru - –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–ê–Ø –¢–û–ß–ù–û–°–¢–¨
–ú–µ–¥–ª–µ–Ω–Ω–µ–µ –Ω–æ –Ω–∞–¥—ë–∂–Ω–µ–µ - 99% —É—Å–ø–µ—Ö –ø–∞—Ä—Å–∏–Ω–≥–∞
"""

import time
import requests
from selenium import webdriver
import pandas as pd
import urllib3
import os
from lxml import html

from pages.listing_page import ListingPage
from config import (
    MAX_PRICE, NUM_THREADS, MAX_PAGES, OUTPUT_FILENAME,
    BASE_URL_TEMPLATE, CHROMEDRIVER_PATH, CHROME_ARGS,
    PAGINATION_DELAY, REQUEST_TIMEOUT
)

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


class SyncCarDetailPage:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π Page Object –¥–ª—è –¥–µ—Ç–∞–ª–µ–π –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
    
    TITLE = '//h1[@class="CardHead__title"]/text()'
    YEAR = '(//a[@class="Link Link_color_black"]/text())[2]'
    MILEAGE = '(//div[@class="CardInfoSummarySimpleRow__content-IIKcj"]/text())[1]'
    OWNERS = '(//div[@class="CardInfoSummarySimpleRow__content-IIKcj"]/text())[2]'
    CONDITION = '//span[contains(text(), "–ò—Å–ø—Ä–∞–≤–Ω") or contains(text(), "–î–µ—Ñ–æ—Ä–º") or contains(text(), "–ë–∏—Ç—ã–µ") or contains(text(), "–ü–µ—Ä–µ–∫—Ä")]/text()'
    TRANSMISSION = '(//div[@class="CardInfoSummaryComplexRow__cellValue-Hka8p"]/text())[2]'
    ENGINE = '(//div[@class="CardInfoSummaryComplexRow__cellValue-Hka8p"]/text())[1]'
    DATE_POSTED = '//div[contains(@class, "CardHead__creationDate")]/text()'
    VIEWS = '//div[contains(@class, "CardHead__views")]/text()'
    PRICE = '//span[@class="OfferPriceCaption__price"]/text()'
    
    def __init__(self, car_url):
        self.car_url = car_url
        self.tree = None
    
    def _load_page(self, session, retry=0, max_retries=5):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
            
            response = session.get(
                self.car_url,
                headers=headers,
                timeout=REQUEST_TIMEOUT,
                verify=False,
                allow_redirects=True
            )
            
            if response.status_code == 200:
                content = response.content
                if content and len(content) > 500:  # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞
                    self.tree = html.fromstring(content)
                    return True
            
            elif response.status_code == 429 and retry < max_retries:
                # Too Many Requests - –∂–¥—ë–º –∏ –ø–æ–≤—Ç–æ—Ä—è–µ–º
                wait_time = 2 ** retry  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                print(f"      ‚è≥ 429 Error - –æ–∂–∏–¥–∞–Ω–∏–µ {wait_time}—Å –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º...")
                time.sleep(wait_time)
                return self._load_page(session, retry + 1, max_retries)
        
        except requests.Timeout:
            if retry < max_retries:
                print(f"      ‚è≥ Timeout - –ø–æ–≤—Ç–æ—Ä {retry + 1}/{max_retries}...")
                time.sleep(1)
                return self._load_page(session, retry + 1, max_retries)
        
        except Exception as e:
            if retry < max_retries:
                print(f"      ‚è≥ –û—à–∏–±–∫–∞: {str(e)[:30]} - –ø–æ–≤—Ç–æ—Ä {retry + 1}/{max_retries}...")
                time.sleep(0.5)
                return self._load_page(session, retry + 1, max_retries)
        
        return False
    
    def _get_text(self, xpath, index=0):
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç –ø–æ XPath"""
        if self.tree is None:
            return "N/A"
        try:
            result = self.tree.xpath(xpath)
            if result and len(result) > index:
                text = str(result[index]).strip()
                return text if text else "N/A"
        except:
            pass
        return "N/A"
    
    def get_date_posted(self):
        """–ü–æ–ª—É—á–∏—Ç—å –¥–∞—Ç—É –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        try:
            if self.tree is None:
                return "N/A"
            
            date_patterns = [
                '//div[contains(@class, "CardHead__creationDate")]/text()',
                '//div[@class="CardHead__infoItem CardHead__creationDate"]/text()',
            ]
            
            for xpath in date_patterns:
                try:
                    result = self.tree.xpath(xpath)
                    if result:
                        for r in result:
                            text = str(r).strip()
                            if text and len(text) > 3:
                                return text
                except:
                    pass
            
            return "N/A"
        except:
            return "N/A"
    
    def get_views(self):
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤"""
        try:
            if self.tree is None:
                return "0"
            
            view_patterns = [
                '//div[contains(@class, "CardHead__views")]/text()',
                '//div[@class="CardHead__infoItem CardHead__views"]/text()',
            ]
            
            for xpath in view_patterns:
                try:
                    result = self.tree.xpath(xpath)
                    if result:
                        for r in result:
                            text = str(r).strip()
                            numbers = ''.join(filter(str.isdigit, text))
                            if numbers:
                                return numbers
                except:
                    pass
            
            return "0"
        except:
            return "0"
    
    def get_condition(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ"""
        try:
            if self.tree is None:
                return "N/A"
            
            conditions = [
                '//span[contains(text(), "–ò—Å–ø—Ä–∞–≤–Ω–æ–µ")]/text()',
                '//span[contains(text(), "–î–µ—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ")]/text()',
                '//span[contains(text(), "–ë–∏—Ç—ã–µ –æ–∫–Ω–∞")]/text()',
                '//span[contains(text(), "–ü–µ—Ä–µ–∫—Ä–∞—à–µ–Ω–æ")]/text()',
                '//span[contains(., "–ò—Å–ø—Ä–∞–≤–Ω") or contains(., "–î–µ—Ñ–æ—Ä–º") or contains(., "–ë–∏—Ç—ã–µ") or contains(., "–ü–µ—Ä–µ–∫—Ä")]/text()',
            ]
            
            for xpath in conditions:
                try:
                    result = self.tree.xpath(xpath)
                    if result:
                        text = str(result[0]).strip()
                        if text and text != "N/A":
                            return text
                except:
                    pass
            
            return "N/A"
        except:
            return "N/A"
    
    def get_price(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Ü–µ–Ω—É"""
        try:
            price_text = self._get_text(self.PRICE)
            if price_text != "N/A":
                numbers = ''.join(filter(str.isdigit, price_text))
                if numbers:
                    return int(numbers)
        except:
            pass
        return 0
    
    def get_car_data(self):
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ"""
        return {
            '–ú–∞—Ä–∫–∞': self._get_text(self.TITLE),
            '–ì–æ–¥ –≤—ã–ø—É—Å–∫–∞': self._get_text(self.YEAR),
            '–ü—Ä–æ–±–µ–≥': self._get_text(self.MILEAGE),
            '–í–ª–∞–¥–µ–ª—å—Ü—ã': self._get_text(self.OWNERS),
            '–°–æ—Å—Ç–æ—è–Ω–∏–µ': self.get_condition(),
            '–ö–æ—Ä–æ–±–∫–∞': self._get_text(self.TRANSMISSION),
            '–î–≤–∏–≥–∞—Ç–µ–ª—å': self._get_text(self.ENGINE),
            '–î–∞—Ç–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è': self.get_date_posted(),
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤': self.get_views(),
            '–¶–µ–Ω–∞': self.get_price(),
            'URL': self.car_url
        }


class SyncAutoRuParser:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä auto.ru - –í–´–°–û–ö–ê–Ø –¢–û–ß–ù–û–°–¢–¨"""
    
    def __init__(self, max_price=MAX_PRICE):
        self.base_url = BASE_URL_TEMPLATE
        self.max_price = max_price
        self.cars = []
        self.driver = None
        self.stats = {'processed': 0, 'errors': 0, 'skipped': 0}
        
        # ‚úÖ –°–æ–∑–¥–∞—ë–º session –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
        self.session = requests.Session()
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=5,
            pool_maxsize=5,
            max_retries=3
        )
        self.session.mount('http://', adapter)
        self.session.mount('https://', adapter)
    
    def setup_driver(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Selenium"""
        options = webdriver.ChromeOptions()
        for arg in CHROME_ARGS:
            options.add_argument(arg)
        
        try:
            if os.path.exists(CHROMEDRIVER_PATH):
                self.driver = webdriver.Chrome(CHROMEDRIVER_PATH, options=options)
            else:
                self.driver = webdriver.Chrome(options=options)
            print("‚úÖ ChromeDriver –∑–∞–≥—Ä—É–∂–µ–Ω")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            raise
    
    def collect_all_links(self, max_pages=MAX_PAGES):
        """–°–æ–±—Ä–∞—Ç—å –í–°–ï —Å—Å—ã–ª–∫–∏"""
        listing_page = ListingPage(self.driver, self.base_url)
        
        print(f"üîç –û–ø—Ä–µ–¥–µ–ª—è—é –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü...")
        total_pages = listing_page.get_total_pages()
        
        if max_pages:
            total_pages = min(total_pages, max_pages)
        
        print(f"üìä –ë—É–¥—É—Ç —Å–æ–±—Ä–∞–Ω—ã —Å—Å—ã–ª–∫–∏ —Å–æ –í–°–ï–• {total_pages} —Å—Ç—Ä–∞–Ω–∏—Ü\n")
        
        all_links = []
        failed_pages = []
        
        for page in range(1, total_pages + 1):
            try:
                print(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}/{total_pages}...", end=' ', flush=True)
                listing_page.open_page(page)
                
                links = listing_page.get_car_links()
                all_links.extend(links)
                print(f"‚úÖ {len(links)} —Å—Å—ã–ª–æ–∫ (–≤—Å–µ–≥–æ: {len(all_links)})")
                
                if PAGINATION_DELAY > 0:
                    time.sleep(PAGINATION_DELAY)
            
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞: {e}")
                failed_pages.append(page)
        
        if failed_pages:
            print(f"\n‚ö†Ô∏è  –û—à–∏–±–∫–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö: {failed_pages}")
        
        return all_links
    
    def parse_car_sync(self, car_url):
        """–ü–∞—Ä—Å–∏—Ç—å –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ"""
        try:
            detail_page = SyncCarDetailPage(car_url)
            if not detail_page._load_page(self.session):
                self.stats['errors'] += 1
                return
            
            car_data = detail_page.get_car_data()
            
            # ‚úÖ –ü—Ä–∏–Ω–∏–º–∞–µ–º –í–°–ï –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            self.cars.append(car_data)
            self.stats['processed'] += 1
        
        except Exception:
            self.stats['errors'] += 1
    
    def parse_all_pages(self, max_pages=MAX_PAGES):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        self.setup_driver()
        
        try:
            all_links = self.collect_all_links(max_pages)
            
            print(f"\n{'='*60}")
            print(f"üìä –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ —Å—Å—ã–ª–æ–∫: {len(all_links)}")
            print(f"‚öôÔ∏è  –°–ò–ù–•–†–û–ù–ù–´–ô –ü–ê–†–°–ò–ù–ì (99% —Ç–æ—á–Ω–æ—Å—Ç—å, –º–µ–¥–ª–µ–Ω–Ω–æ)")
            print(f"{'='*60}\n")
            
            start_parsing = time.time()
            
            for idx, url in enumerate(all_links, 1):
                # ‚úÖ –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 50 –æ–±—ä—è–≤–ª–µ–Ω–∏–π
                if idx % 50 == 0:
                    success_rate = (self.stats['processed'] / (self.stats['processed'] + self.stats['errors'])) * 100 if (self.stats['processed'] + self.stats['errors']) > 0 else 0
                    print(f"  ‚öôÔ∏è  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {idx}/{len(all_links)} | –£—Å–ø–µ—Ö: {success_rate:.1f}%")
                
                # ‚úÖ –ü–∞—Ä—Å–∏–º –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
                self.parse_car_sync(url)
                
                # ‚úÖ –ó–ê–î–ï–†–ñ–ö–ê 0.5 —Å–µ–∫ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
                time.sleep(0.5)
            
            elapsed_parsing = time.time() - start_parsing
            print(f"\n‚öôÔ∏è  –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–Ω—è–ª: {elapsed_parsing:.1f} —Å–µ–∫")
        
        except KeyboardInterrupt:
            print("\n\n‚ö†Ô∏è  –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        
        finally:
            self.driver.quit()
            print("üî¥ Browser –∑–∞–∫—Ä—ã—Ç")
        
        return self.cars
    
    def save_to_excel(self, filename=OUTPUT_FILENAME):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –í–°–ï –¥–∞–Ω–Ω—ã–µ"""
        if not self.cars:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return
        
        start_save = time.time()
        print(f"\n‚è≥ –°–æ—Ö—Ä–∞–Ω—è—é {len(self.cars)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π...")
        
        df = pd.DataFrame(self.cars)
        
        # ‚úÖ –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        try:
            df['–î–∞—Ç–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è'] = pd.to_datetime(df['–î–∞—Ç–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è'], 
                                                   format='%d %B %Y', 
                                                   errors='coerce')
            df = df.sort_values('–î–∞—Ç–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è', ascending=False, na_position='last')
            df['–î–∞—Ç–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è'] = df['–î–∞—Ç–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è'].dt.strftime('%d.%m.%Y')
        except:
            pass
        
        # ‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–æ—Å–º–æ—Ç—Ä—ã –≤ —á–∏—Å–ª–∞
        try:
            df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤'] = pd.to_numeric(df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤'], errors='coerce').fillna(0).astype(int)
        except:
            pass
        
        df = df.drop('URL', axis=1)
        df.to_excel(filename, index=False, engine='openpyxl')
        
        elapsed_save = time.time() - start_save
        
        print(f"\n‚úÖ –î–ê–ù–ù–´–ï –°–û–•–†–ê–ù–ï–ù–´!")
        print(f"üìä –ó–∞–ø–∏—Å–µ–π –≤ —Ñ–∞–π–ª–µ: {len(df)}")
        print(f"üìà –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.stats['processed']}")
        print(f"‚ùå –û—à–∏–±–æ–∫: {self.stats['errors']}")
        
        success_rate = (self.stats['processed'] / (self.stats['processed'] + self.stats['errors'])) * 100 if (self.stats['processed'] + self.stats['errors']) > 0 else 0
        print(f"üìä –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate:.1f}% ‚úÖ")
        
        if len(df) > 0:
            print(f"\nüí∞ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ü–µ–Ω–∞–º:")
            print(f"   –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {df['–¶–µ–Ω–∞'].mean():,.0f} —Ä—É–±")
            print(f"   –ú–∏–Ω–∏–º—É–º: {df['–¶–µ–Ω–∞'].min():,.0f} —Ä—É–±")
            print(f"   –ú–∞–∫—Å–∏–º—É–º: {df['–¶–µ–Ω–∞'].max():,.0f} —Ä—É–±")
            print(f"   –û–±—ä—è–≤–ª–µ–Ω–∏–π –±–µ–∑ —Ü–µ–Ω—ã: {(df['–¶–µ–Ω–∞'] == 0).sum()}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    total_start = time.time()
    
    parser = SyncAutoRuParser(max_price=MAX_PRICE)
    
    print("\n" + "="*60)
    print("üöó –°–ò–ù–•–†–û–ù–ù–´–ô –ü–ê–†–°–ï–† AUTO.RU")
    print("   99% –¢–û–ß–ù–û–°–¢–¨ - –ù–ê–î–Å–ñ–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê")
    print("="*60)
    print(f"üí∞ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞: {MAX_PRICE:,} —Ä—É–±")
    print(f"‚öôÔ∏è  –†–µ–∂–∏–º: –°–ò–ù–•–†–û–ù–ù–´–ô (–º–µ–¥–ª–µ–Ω–Ω—ã–π –Ω–æ —Ç–æ—á–Ω—ã–π)")
    print("="*60)
    
    parser.parse_all_pages(max_pages=MAX_PAGES)
    parser.save_to_excel(OUTPUT_FILENAME)
    
    total_elapsed = time.time() - total_start
    
    print("\n" + "="*60)
    print(f"‚úÖ –ü–ê–†–°–ò–ù–ì –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–Å–ù!")
    print("="*60)
    print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_elapsed:.1f} —Å–µ–∫ (~{total_elapsed/60:.1f} –º–∏–Ω)")
    print(f"üìä –í—Å–µ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –≤ —Ñ–∞–π–ª–µ: {len(parser.cars)}")
    
    if total_elapsed > 0 and len(parser.cars) > 0:
        speed = len(parser.cars) / total_elapsed
        print(f"‚öôÔ∏è  –°–∫–æ—Ä–æ—Å—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–∞: ~{speed:.2f} –æ–±—ä—è–≤–ª/—Å–µ–∫ (–º–µ–¥–ª–µ–Ω–Ω–æ –Ω–æ –Ω–∞–¥—ë–∂–Ω–æ)")
    
    print("="*60)
    print(f"üìÅ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {OUTPUT_FILENAME}\n")


if __name__ == "__main__":
    main()
